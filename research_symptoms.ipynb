{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ec7a1e-844b-4890-9a5b-1327e8649e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Common disease group</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease Group</th>\n",
       "      <th>Dosha Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urethritis (infectious, noninfectious)</td>\n",
       "      <td>Urinary tract infections</td>\n",
       "      <td>Burning urination; pain during urination (dysu...</td>\n",
       "      <td>Lower urinary tract infection (UTI)</td>\n",
       "      <td>Vata|Pitta|Kapha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cystitis (acute bacterial cystitis)</td>\n",
       "      <td>Urinary tract infections</td>\n",
       "      <td>Burning urination; frequent urination; urgency...</td>\n",
       "      <td>Lower UTI (bladder infection)</td>\n",
       "      <td>Pitta|Vata|Kapha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interstitial cystitis (nonbacterial)</td>\n",
       "      <td>Urinary tract infections</td>\n",
       "      <td>Chronic pelvic pain; bladder pressure; frequen...</td>\n",
       "      <td>Nonbacterial bladder inflammation</td>\n",
       "      <td>Vata|Pitta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pyelonephritis (acute bacterial)</td>\n",
       "      <td>Urinary tract infections</td>\n",
       "      <td>High fever; chills; flank pain; nausea; vomiti...</td>\n",
       "      <td>Upper UTI (kidney infection)</td>\n",
       "      <td>Pitta|Vata|Kapha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chronic pyelonephritis</td>\n",
       "      <td>Urinary tract infections</td>\n",
       "      <td>Vague flank/abdominal pain; malaise; recurrent...</td>\n",
       "      <td>Chronic upper UTI</td>\n",
       "      <td>Pitta|Vata|Kapha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Disease      Common disease group  \\\n",
       "0  Urethritis (infectious, noninfectious)  Urinary tract infections   \n",
       "1     Cystitis (acute bacterial cystitis)  Urinary tract infections   \n",
       "2    Interstitial cystitis (nonbacterial)  Urinary tract infections   \n",
       "3        Pyelonephritis (acute bacterial)  Urinary tract infections   \n",
       "4                  Chronic pyelonephritis  Urinary tract infections   \n",
       "\n",
       "                                            Symptoms  \\\n",
       "0  Burning urination; pain during urination (dysu...   \n",
       "1  Burning urination; frequent urination; urgency...   \n",
       "2  Chronic pelvic pain; bladder pressure; frequen...   \n",
       "3  High fever; chills; flank pain; nausea; vomiti...   \n",
       "4  Vague flank/abdominal pain; malaise; recurrent...   \n",
       "\n",
       "                         Disease Group       Dosha Types  \n",
       "0  Lower urinary tract infection (UTI)  Vata|Pitta|Kapha  \n",
       "1        Lower UTI (bladder infection)  Pitta|Vata|Kapha  \n",
       "2    Nonbacterial bladder inflammation        Vata|Pitta  \n",
       "3         Upper UTI (kidney infection)  Pitta|Vata|Kapha  \n",
       "4                    Chronic upper UTI  Pitta|Vata|Kapha  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "\n",
    "# Show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7191319e-f794-4807-8967-6b1409342743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disease Group\n",
       "Muscular dystrophy                                       16\n",
       "Congenital heart disease                                 14\n",
       "Infectious disease                                       10\n",
       "Congenital myopathy                                      10\n",
       "Cancer (Head and neck)                                   10\n",
       "                                                         ..\n",
       "Bacterial UTI (lower or upper)                            1\n",
       "Bacterial UTI (lower/upper)                               1\n",
       "female reproductive disorder (cyclical hormonal)          1\n",
       "female reproductive disorder (hormonal mood disorder)     1\n",
       "Simple lower UTI                                          1\n",
       "Name: count, Length: 958, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Disease Group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cfdad1-35d9-446f-a7f8-8262e3769ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Common disease group\n",
       "Urinary tract infections                 100\n",
       "Muscular disorders                       100\n",
       "Cardiomyopathies                         100\n",
       "zoonotic diseases                        100\n",
       "Liver disease                            100\n",
       "Hematological diseases                   100\n",
       "Cardiovascular diseases                  100\n",
       "Cancer and neoplasms                     100\n",
       "Eye diseases                             100\n",
       "Ear diseases                             100\n",
       "Mental health / Psychiatric disorders    100\n",
       "Endocrine and Metabolic Diseases         100\n",
       "Nutritional Deficiency Diseases          100\n",
       "Reproductive system diseases             100\n",
       "Tropical diseases                         84\n",
       "tropical diseases                         16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Common disease group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e5d648-2c2c-4606-9b9d-39c71ab30888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disease\n",
       "Urethritis (infectious, noninfectious)                                    1\n",
       "Cystitis (acute bacterial cystitis)                                       1\n",
       "Interstitial cystitis (nonbacterial)                                      1\n",
       "Pyelonephritis (acute bacterial)                                          1\n",
       "Chronic pyelonephritis                                                    1\n",
       "                                                                         ..\n",
       "Interstitial cystitis (bladder pain syndrome with reproductive impact)    1\n",
       "Fitz-Hugh–Curtis syndrome                                                 1\n",
       "Hematosalpinx                                                             1\n",
       "Prostatic intraepithelial neoplasia (PIN)                                 1\n",
       "Female genital tuberculosis (FGTB)                                        1\n",
       "Name: count, Length: 1500, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Disease\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984600cd-0ad8-4dc8-81bb-68c9ce089810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dosha Types\n",
       "vata                446\n",
       "pitta               325\n",
       "vata|pitta           83\n",
       "vata;pitta           81\n",
       "kapha                76\n",
       "Pitta                58\n",
       "vata;kapha           55\n",
       "vata|kapha           52\n",
       "pitta;vata           47\n",
       "pitta;kapha          30\n",
       "kapha;vata           29\n",
       "Kapha                25\n",
       "pitta|vata|kapha     23\n",
       "vata|pitta|kapha     17\n",
       "kapha|vata           16\n",
       "pitta|vata           13\n",
       "Pitta;Kapha          13\n",
       "kapha;pitta          12\n",
       "Pitta|Vata           11\n",
       "Vata|Pitta|Kapha     11\n",
       "vata;pitta;kapha     10\n",
       "Pitta|Vata|Kapha     10\n",
       "Pitta|Kapha           7\n",
       "vata|kapha|pitta      7\n",
       "pitta|kapha|vata      6\n",
       "kapha|pitta|vata      6\n",
       "pitta;vata;kapha      5\n",
       "Vata|Pitta            4\n",
       "Pitta|Kapha|Vata      4\n",
       "vata;kapha;pitta      4\n",
       "pitta;kapha;vata      3\n",
       "Kapha;Pitta           3\n",
       "Kapha|Pitta|Vata      3\n",
       "kapha|pitta           1\n",
       "pitta|kapha           1\n",
       "kapha|vata|pitta      1\n",
       "Vata;Pitta            1\n",
       "kapha;pitta;vata      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Dosha Types\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a20c022-2ce5-4055-9527-4b4c5e9998cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original unique dosha combos (sample 20):\n",
      "['Vata|Pitta|Kapha' 'Pitta|Vata|Kapha' 'Vata|Pitta' 'Pitta|Kapha'\n",
      " 'Pitta|Kapha|Vata' 'Pitta|Vata' 'Kapha|Pitta|Vata' 'kapha|pitta|vata'\n",
      " 'pitta|kapha|vata' 'vata|pitta|kapha' 'pitta|vata|kapha' 'vata|pitta'\n",
      " 'kapha|pitta' 'kapha|vata|pitta' 'pitta|vata' 'kapha|vata' 'vata'\n",
      " 'vata|kapha' 'vata|kapha|pitta' 'kapha']\n",
      "\n",
      "Normalized unique dosha combos:\n",
      "['tridosha' 'vata|pitta' 'pitta|kapha' 'vata|kapha' 'vata' 'kapha' 'pitta']\n",
      "\n",
      "Counts after normalization:\n",
      "Dosha_Clean\n",
      "vata           446\n",
      "pitta          383\n",
      "vata|pitta     240\n",
      "vata|kapha     152\n",
      "tridosha       111\n",
      "kapha          101\n",
      "pitta|kapha     67\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rows with unrecognized/empty dosha after cleaning:\n",
      "Empty DataFrame\n",
      "Columns: [Disease, Common disease group, Symptoms, Disease Group, Dosha Types, Dosha_Clean]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "\n",
    "# Canonical order we want to enforce in 2-dosha combos\n",
    "ORDER = [\"vata\", \"pitta\", \"kapha\"]\n",
    "ORDER_SET = set(ORDER)\n",
    "\n",
    "def normalize_dosha(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    # If it's any tridosha wording, normalize straight away\n",
    "    # (covers 'tridosha', 'trisosha', 'tri dosha', etc.)\n",
    "    if \"tridosha\" in s or \"trisosha\" in s or re.search(r\"\\btri\\s*dosha\\b\", s):\n",
    "        return \"tridosha\"\n",
    "\n",
    "    # Replace separators ; , / + with '|', drop spaces, and strip odd chars\n",
    "    s = re.sub(r\"[;,+/]+\", \"|\", s)     # unify to '|'\n",
    "    s = s.replace(\" \", \"\")\n",
    "    s = re.sub(r\"[^a-z|]\", \"\", s)      # keep only letters and '|'\n",
    "\n",
    "    # Split to parts, remove empties, keep only known doshas\n",
    "    parts = [p for p in s.split(\"|\") if p]\n",
    "    parts = [p for p in parts if p in ORDER_SET]\n",
    "\n",
    "    if not parts:\n",
    "        return pd.NA\n",
    "\n",
    "    # Deduplicate and enforce canonical order vata -> pitta -> kapha\n",
    "    present = [d for d in ORDER if d in parts]\n",
    "\n",
    "    # Any 3 doshas -> 'tridosha'\n",
    "    if len(present) >= 3:\n",
    "        return \"tridosha\"\n",
    "\n",
    "    # 1 or 2 doshas -> join with '|'\n",
    "    return \"|\".join(present)\n",
    "\n",
    "# Apply normalization\n",
    "df[\"Dosha_Clean\"] = df[\"Dosha Types\"].apply(normalize_dosha)\n",
    "\n",
    "# Inspect results\n",
    "print(\"Original unique dosha combos (sample 20):\")\n",
    "print(df[\"Dosha Types\"].unique()[:20])\n",
    "\n",
    "print(\"\\nNormalized unique dosha combos:\")\n",
    "print(df[\"Dosha_Clean\"].unique())\n",
    "\n",
    "print(\"\\nCounts after normalization:\")\n",
    "print(df[\"Dosha_Clean\"].value_counts(dropna=False))\n",
    "\n",
    "# (Optional) Check rows that became NA after cleaning (unexpected formats)\n",
    "print(\"\\nRows with unrecognized/empty dosha after cleaning:\")\n",
    "print(df[df[\"Dosha_Clean\"].isna()].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba0b208-1437-4fd5-b745-7d061c6eef7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Disease      Common disease group  \\\n",
      "0  Urethritis (infectious, noninfectious)  Urinary tract infections   \n",
      "1     Cystitis (acute bacterial cystitis)  Urinary tract infections   \n",
      "2    Interstitial cystitis (nonbacterial)  Urinary tract infections   \n",
      "3        Pyelonephritis (acute bacterial)  Urinary tract infections   \n",
      "4                  Chronic pyelonephritis  Urinary tract infections   \n",
      "\n",
      "                                            Symptoms  \\\n",
      "0  Burning urination; pain during urination (dysu...   \n",
      "1  Burning urination; frequent urination; urgency...   \n",
      "2  Chronic pelvic pain; bladder pressure; frequen...   \n",
      "3  High fever; chills; flank pain; nausea; vomiti...   \n",
      "4  Vague flank/abdominal pain; malaise; recurrent...   \n",
      "\n",
      "                         Disease Group       Dosha Types  \n",
      "0  Lower urinary tract infection (UTI)  Vata|Pitta|Kapha  \n",
      "1        Lower UTI (bladder infection)  Pitta|Vata|Kapha  \n",
      "2    Nonbacterial bladder inflammation        Vata|Pitta  \n",
      "3         Upper UTI (kidney infection)  Pitta|Vata|Kapha  \n",
      "4                    Chronic upper UTI  Pitta|Vata|Kapha  \n",
      "Shape of data: (1500, 5)\n",
      "Columns: ['Disease', 'Common disease group', 'Symptoms', 'Disease Group', 'Dosha Types']\n",
      "\n",
      "Missing values in each column:\n",
      " Disease                 0\n",
      "Common disease group    0\n",
      "Symptoms                0\n",
      "Disease Group           0\n",
      "Dosha Types             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Explore Data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file (update the path if needed)\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "\n",
    "# Show the first 5 rows (to get a quick look at the data)\n",
    "print(df.head())\n",
    "\n",
    "# Show the number of rows and columns\n",
    "print(\"Shape of data:\", df.shape)\n",
    "\n",
    "# Show column names\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b5d8536-4849-42f3-aeac-7eb1e525811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (1500, 2717)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert symptoms (text) into numbers using TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Select the text column (symptoms)\n",
    "X = df[\"Symptoms\"]\n",
    "\n",
    "# Create a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer and transform the symptoms\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Show the shape of the resulting matrix\n",
    "print(\"TF-IDF matrix shape:\", X_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8692fce6-798d-436a-91cb-94fcfa3717de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 95.00%\n",
      "Random Forest: 100.00%\n",
      "Decision Tree: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Training and evaluating different models\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Features (X) = Symptoms\n",
    "X = df[\"Symptoms\"]\n",
    "\n",
    "# Labels (y) = Disease group (English name) for now\n",
    "y = df[\"Common disease group\"]\n",
    "\n",
    "# Define the models we want to test\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer()),  # Step 1: Convert text to numbers\n",
    "        (\"clf\", clf)                   # Step 2: Train model\n",
    "    ])\n",
    "    pipe.fit(X, y)                      # Train\n",
    "    y_pred = pipe.predict(X)            # Predict on same data\n",
    "    acc = accuracy_score(y, y_pred)     # Check accuracy\n",
    "    print(f\"{name}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d39d1b78-c486-4015-a7da-f604e7c8ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "\n",
    "# Canonical order\n",
    "ORDER = [\"vata\", \"pitta\", \"kapha\"]\n",
    "ORDER_SET = set(ORDER)\n",
    "\n",
    "def normalize_dosha(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    if \"tridosha\" in s or \"trisosha\" in s or re.search(r\"\\btri\\s*dosha\\b\", s):\n",
    "        return \"tridosha\"\n",
    "\n",
    "    s = re.sub(r\"[;,+/]+\", \"|\", s)\n",
    "    s = s.replace(\" \", \"\")\n",
    "    s = re.sub(r\"[^a-z|]\", \"\", s)\n",
    "\n",
    "    parts = [p for p in s.split(\"|\") if p]\n",
    "    parts = [p for p in parts if p in ORDER_SET]\n",
    "\n",
    "    if not parts:\n",
    "        return pd.NA\n",
    "\n",
    "    present = [d for d in ORDER if d in parts]\n",
    "    if len(present) >= 3:\n",
    "        return \"tridosha\"\n",
    "    return \"|\".join(present)\n",
    "\n",
    "# 🔹 Create cleaned column\n",
    "df[\"Dosha_Clean\"] = df[\"Dosha Types\"].apply(normalize_dosha)\n",
    "\n",
    "# ✅ Now train\n",
    "X = df[\"Symptoms\"]\n",
    "y = df[\"Dosha_Clean\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd2e746a-f64e-4499-bcdb-ac78ec81ca9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train (fit-on-all) accuracy ===\n",
      "Logistic Regression: 80.87%\n",
      "Random Forest: 99.60%\n",
      "Decision Tree: 99.60%\n",
      "\n",
      "=== Hold-out (train/test split) accuracy ===\n",
      "Logistic Regression: 62.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       kapha       1.00      0.30      0.46        20\n",
      "       pitta       0.63      0.74      0.68        77\n",
      " pitta|kapha       1.00      0.08      0.14        13\n",
      "    tridosha       0.83      0.68      0.75        22\n",
      "        vata       0.59      0.89      0.71        89\n",
      "  vata|kapha       0.61      0.35      0.45        31\n",
      "  vata|pitta       0.52      0.35      0.42        48\n",
      "\n",
      "    accuracy                           0.62       300\n",
      "   macro avg       0.74      0.49      0.52       300\n",
      "weighted avg       0.65      0.62      0.59       300\n",
      "\n",
      "Random Forest: 64.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       kapha       0.83      0.25      0.38        20\n",
      "       pitta       0.64      0.79      0.71        77\n",
      " pitta|kapha       1.00      0.15      0.27        13\n",
      "    tridosha       0.84      0.73      0.78        22\n",
      "        vata       0.61      0.84      0.71        89\n",
      "  vata|kapha       0.67      0.39      0.49        31\n",
      "  vata|pitta       0.59      0.46      0.52        48\n",
      "\n",
      "    accuracy                           0.64       300\n",
      "   macro avg       0.74      0.52      0.55       300\n",
      "weighted avg       0.67      0.64      0.62       300\n",
      "\n",
      "Decision Tree: 55.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       kapha       0.42      0.25      0.31        20\n",
      "       pitta       0.63      0.69      0.66        77\n",
      " pitta|kapha       0.43      0.23      0.30        13\n",
      "    tridosha       0.54      0.59      0.57        22\n",
      "        vata       0.59      0.61      0.60        89\n",
      "  vata|kapha       0.41      0.39      0.40        31\n",
      "  vata|pitta       0.50      0.54      0.52        48\n",
      "\n",
      "    accuracy                           0.55       300\n",
      "   macro avg       0.50      0.47      0.48       300\n",
      "weighted avg       0.54      0.55      0.55       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Ensure Dosha_Clean exists\n",
    "# -----------------------------\n",
    "ORDER = [\"vata\", \"pitta\", \"kapha\"]\n",
    "ORDER_SET = set(ORDER)\n",
    "\n",
    "def normalize_dosha(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    # tridosha variations\n",
    "    if \"tridosha\" in s or \"trisosha\" in s or re.search(r\"\\btri\\s*dosha\\b\", s):\n",
    "        return \"tridosha\"\n",
    "\n",
    "    # unify separators and strip non-letters/pipes\n",
    "    s = re.sub(r\"[;,+/]+\", \"|\", s)\n",
    "    s = s.replace(\" \", \"\")\n",
    "    s = re.sub(r\"[^a-z|]\", \"\", s)\n",
    "\n",
    "    parts = [p for p in s.split(\"|\") if p]\n",
    "    parts = [p for p in parts if p in ORDER_SET]\n",
    "    if not parts:\n",
    "        return pd.NA\n",
    "\n",
    "    present = [d for d in ORDER if d in parts]\n",
    "    if len(present) >= 3:\n",
    "        return \"tridosha\"\n",
    "    return \"|\".join(present)\n",
    "\n",
    "if \"Dosha_Clean\" not in df.columns:\n",
    "    df[\"Dosha_Clean\"] = df[\"Dosha Types\"].apply(normalize_dosha)\n",
    "\n",
    "# Drop rows with missing/empty labels or symptoms\n",
    "df = df[~df[\"Dosha_Clean\"].isna()].copy()\n",
    "df = df[df[\"Symptoms\"].astype(str).str.strip().ne(\"\")].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Features & labels\n",
    "# -----------------------------\n",
    "X = df[\"Symptoms\"]\n",
    "y = df[\"Dosha_Clean\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Models to test\n",
    "# -----------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 5) TRAIN accuracy (fit & predict on full data)\n",
    "#    — matches your earlier evaluation style\n",
    "# -----------------------------\n",
    "print(\"=== Train (fit-on-all) accuracy ===\")\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer()),\n",
    "        (\"clf\", clf)\n",
    "    ])\n",
    "    pipe.fit(X, y)\n",
    "    y_pred = pipe.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    print(f\"{name}: {acc:.2%}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Optional: Hold-out evaluation (recommended)\n",
    "# -----------------------------\n",
    "do_holdout = True\n",
    "if do_holdout:\n",
    "    print(\"\\n=== Hold-out (train/test split) accuracy ===\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    for name, clf in models.items():\n",
    "        pipe = Pipeline([\n",
    "            (\"tfidf\", TfidfVectorizer()),\n",
    "            (\"clf\", clf)\n",
    "        ])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{name}: {acc:.2%}\")\n",
    "        # Per-class metrics (comment out if too verbose)\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d65fc20-6b9a-4227-95dd-aa1d9070f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: disease_prediction_model_en_group.pkl\n"
     ]
    }
   ],
   "source": [
    "# ---------- English Group Model ----------\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"data/symptoms.csv\")   # adjust path to your CSV\n",
    "\n",
    "X_en = df[\"Symptoms\"].astype(str)\n",
    "y_en = df[\"Common disease group\"]\n",
    "\n",
    "pipeline_en = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=50_000,\n",
    "        dtype=np.float32\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        max_iter=300,\n",
    "        C=2.0,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_en.fit(X_en, y_en)\n",
    "joblib.dump(pipeline_en, \"disease_prediction_model_en_group.pkl\", compress=3)\n",
    "print(\"Saved: disease_prediction_model_en_group.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e2fab-38ce-492d-af73-24f644ac3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Disease Model ----------\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "\n",
    "X_disease = df[\"Symptom\"].astype(str)\n",
    "y_disease = df[\"Disease\"]\n",
    "\n",
    "pipeline_disease = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=50_000,\n",
    "        dtype=np.float32\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        max_iter=300,\n",
    "        C=2.0,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_disease.fit(X_disease, y_disease)\n",
    "joblib.dump(pipeline_disease, \"disease_prediction_model_disease.pkl\", compress=3)\n",
    "print(\"Saved: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "048c30ae-3231-4263-9753-e107e2ca8f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dosha class distribution:\n",
      " Dosha_Clean\n",
      "vata           446\n",
      "pitta          383\n",
      "vata|pitta     240\n",
      "vata|kapha     152\n",
      "tridosha       111\n",
      "kapha          101\n",
      "pitta|kapha     67\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwares\\python\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "D:\\softwares\\python\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: dosha_classification_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# ---------- Dosha Model (robust) ----------\n",
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "df.rename(columns=lambda c: str(c).strip(), inplace=True)  # guard against stray spaces\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Ensure Dosha_Clean exists\n",
    "# -----------------------------\n",
    "ORDER = [\"vata\", \"pitta\", \"kapha\"]\n",
    "ORDER_SET = set(ORDER)\n",
    "\n",
    "def normalize_dosha(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    # handle tridosha variants\n",
    "    if \"tridosha\" in s or \"trisosha\" in s or re.search(r\"\\btri\\s*dosha\\b\", s):\n",
    "        return \"tridosha\"\n",
    "\n",
    "    # unify separators to '|', remove spaces, keep only letters and '|'\n",
    "    s = re.sub(r\"[;,+/]+\", \"|\", s)\n",
    "    s = s.replace(\" \", \"\")\n",
    "    s = re.sub(r\"[^a-z|]\", \"\", s)\n",
    "\n",
    "    parts = [p for p in s.split(\"|\") if p]\n",
    "    parts = [p for p in parts if p in ORDER_SET]\n",
    "    if not parts:\n",
    "        return pd.NA\n",
    "\n",
    "    present = [d for d in ORDER if d in parts]\n",
    "    if len(present) >= 3:\n",
    "        return \"tridosha\"\n",
    "    return \"|\".join(present)\n",
    "\n",
    "# create Dosha_Clean if missing\n",
    "if \"Dosha_Clean\" not in df.columns:\n",
    "    source_col = \"Dosha Types\" if \"Dosha Types\" in df.columns else None\n",
    "    if source_col is None:\n",
    "        raise KeyError(\"Neither 'Dosha_Clean' nor 'Dosha Types' column found in the CSV.\")\n",
    "    df[\"Dosha_Clean\"] = df[source_col].apply(normalize_dosha)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Clean rows (no empty symptoms/labels)\n",
    "# -----------------------------\n",
    "df[\"Symptoms\"] = df[\"Symptoms\"].astype(str).fillna(\"\").str.strip()\n",
    "df = df[(df[\"Symptoms\"] != \"\") & (~df[\"Dosha_Clean\"].isna())].copy()\n",
    "\n",
    "# Optional: peek at class balance\n",
    "print(\"Dosha class distribution:\\n\", df[\"Dosha_Clean\"].value_counts())\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Features & labels\n",
    "# -----------------------------\n",
    "X_dosha = df[\"Symptoms\"]\n",
    "y_dosha = df[\"Dosha_Clean\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Pipeline & training\n",
    "# -----------------------------\n",
    "pipeline_dosha = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=50_000,\n",
    "        dtype=np.float32\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        max_iter=2000,          # give it room to converge\n",
    "        C=2.0,\n",
    "        class_weight=\"balanced\",# helpful if classes are imbalanced\n",
    "        multi_class=\"auto\",\n",
    "        # NOTE: n_jobs is only used by 'liblinear'; 'saga' ignores it.\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_dosha.fit(X_dosha, y_dosha)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Save model\n",
    "# -----------------------------\n",
    "out_path = \"dosha_classification_model.pkl\"\n",
    "joblib.dump(pipeline_dosha, out_path, compress=3)\n",
    "print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23895b54-a241-43d5-9a98-3c8071ff01ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in d:\\softwares\\python\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\softwares\\python\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\softwares\\python\\lib\\site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\softwares\\python\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in d:\\softwares\\python\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in d:\\softwares\\python\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: colorama in d:\\softwares\\python\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\softwares\\python\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\softwares\\python\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\softwares\\python\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\softwares\\python\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\softwares\\python\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\softwares\\python\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\softwares\\python\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in d:\\softwares\\python\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.14.1)\n",
      "Requirement already satisfied: wcwidth in d:\\softwares\\python\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\softwares\\python\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\softwares\\python\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\softwares\\python\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\softwares\\python\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cce509a-22ad-4830-b69e-8e257cf822ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e83988380aa4343b26a3e745a5c6f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.IntSlider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69f94371-de8c-43f5-b028-515efa585ffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c7b3008e554bd1a9b58dde173e3a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Symptoms:', layout=Layout(width='80%'), placeholder=\"Type symptoms (e.g., 'burning…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7d1fcc0c3b4d63bb8083e4fe21aa45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(layout=Layout(width='80%'), options=(), rows=6, value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96cdb08ec6345a69ccb370e91243b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Predict Disease', layout=Layout(height='50px', width='200px'), sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b951e12bc80d4dd0a889517167995941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict Disease Name from entered symptoms (with suggestions + fuzzy fallback)\n",
    "import pandas as pd, difflib\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "df[\"Symptoms\"] = df[\"Symptoms\"].astype(str)\n",
    "\n",
    "# Build unique symptom list and lookup\n",
    "SYMPTOMS = sorted(set(df[\"Symptoms\"].dropna().astype(str).tolist()))\n",
    "SYMPTOM_LOOKUP = {s.strip().lower(): s for s in SYMPTOMS}\n",
    "\n",
    "# --- Suggestion helper (prefix + substring + fuzzy) ---\n",
    "def get_suggestions(query, k=12):\n",
    "    q = (query or \"\").strip().lower()\n",
    "    if not q:\n",
    "        return []\n",
    "    prefix = [s for s in SYMPTOMS if s.lower().startswith(q)]\n",
    "    substr = [s for s in SYMPTOMS if q in s.lower() and s not in prefix]\n",
    "    fuzzy  = difflib.get_close_matches(q, SYMPTOMS, n=k*2, cutoff=0.6)\n",
    "    fuzzy  = [s for s in fuzzy if s not in prefix and s not in substr]\n",
    "    out, seen = [], set()\n",
    "    for s in prefix + substr + fuzzy:\n",
    "        if s not in seen:\n",
    "            out.append(s); seen.add(s)\n",
    "        if len(out) >= k:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def resolve_exact(text):\n",
    "    return SYMPTOM_LOOKUP.get((text or \"\").strip().lower())\n",
    "\n",
    "# --- Widgets ---\n",
    "inp = widgets.Text(\n",
    "    placeholder=\"Type symptoms (e.g., 'burning urination; frequency; urgency')\",\n",
    "    description=\"Symptoms:\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "sugg_list = widgets.Select(\n",
    "    options=[],\n",
    "    rows=6,\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "pred_btn = widgets.Button(\n",
    "    description=\"Predict Disease\",\n",
    "    button_style=\"success\",\n",
    "    layout=widgets.Layout(width=\"200px\", height=\"50px\")\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "# --- Events ---\n",
    "def on_text_change(change):\n",
    "    suggs = get_suggestions(change[\"new\"], k=12)\n",
    "    sugg_list.options = suggs\n",
    "\n",
    "def on_select_change(change):\n",
    "    if change[\"new\"]:\n",
    "        inp.value = change[\"new\"]\n",
    "\n",
    "def on_predict(_):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        user_text = (inp.value or \"\").strip()\n",
    "        if not user_text:\n",
    "            display(Markdown(\"> ⚠️ Please enter symptoms (or select from the suggestions).\"))\n",
    "            return\n",
    "\n",
    "        # 1) Try exact match to a known 'Symptoms' string\n",
    "        canon = resolve_exact(user_text)\n",
    "\n",
    "        # 2) If no exact match, fuzzy-match to closest known symptom text\n",
    "        matched_note = \"\"\n",
    "        if not canon:\n",
    "            best = difflib.get_close_matches(user_text, SYMPTOMS, n=1, cutoff=0.55)\n",
    "            if best:\n",
    "                canon = best[0]\n",
    "                matched_note = f\"\\n> *No exact match found. Using closest known symptoms:* `{canon}`\"\n",
    "            else:\n",
    "                display(Markdown(\"> ❌ No similar symptoms found in the CSV. Try typing differently or pick from suggestions.\"))\n",
    "                return\n",
    "\n",
    "        # Fetch all diseases for the matched symptom text (usually one)\n",
    "        diseases = sorted(set(df.loc[df[\"Symptoms\"] == canon, \"Disease\"].astype(str)))\n",
    "        if not diseases:\n",
    "            display(Markdown(f\"> ❌ Couldn’t find a disease for symptoms: `{canon}`\"))\n",
    "            return\n",
    "\n",
    "        # Render result\n",
    "        disease_list_md = \"\\n\".join([f\"- `{d}`\" for d in diseases])\n",
    "        display(Markdown(\n",
    "f\"\"\"### 🧾 Predicted Disease\n",
    "**Entered symptoms:** `{user_text}`{matched_note}\n",
    "\n",
    "**Result(s):**\n",
    "{disease_list_md}\n",
    "\"\"\"\n",
    "        ))\n",
    "\n",
    "# Wire up\n",
    "inp.observe(on_text_change, names=\"value\")\n",
    "sugg_list.observe(on_select_change, names=\"value\")\n",
    "pred_btn.on_click(on_predict)\n",
    "\n",
    "# Initial render\n",
    "display(inp, sugg_list, pred_btn, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b3cecca-d6ff-422a-b4bc-6726c43c539f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea3c8c505634f5db5525c67590a21ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Symptoms:', layout=Layout(width='80%'), placeholder=\"Type symptoms (e.g., 'burning…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d4efea5a6c4710bc86a2445f1d657a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(layout=Layout(width='80%'), options=(), rows=6, value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc014e1536a94984befc91ef7e3286ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Predict Common Group', layout=Layout(height='50px', width='220px'), s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7f54ece04548cfb5d5fcf706ab4772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict Common disease group from entered symptoms (with suggestions + fuzzy fallback)\n",
    "import pandas as pd, difflib\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "df[\"Symptoms\"] = df[\"Symptoms\"].astype(str)\n",
    "df[\"Common disease group\"] = df[\"Common disease group\"].astype(str)\n",
    "\n",
    "# Build unique symptom list and lookup\n",
    "SYMPTOMS = sorted(set(df[\"Symptoms\"].dropna().tolist()))\n",
    "SYMPTOM_LOOKUP = {s.strip().lower(): s for s in SYMPTOMS}\n",
    "\n",
    "# --- Suggestion helper (prefix + substring + fuzzy) ---\n",
    "def get_suggestions(query, k=12):\n",
    "    q = (query or \"\").strip().lower()\n",
    "    if not q:\n",
    "        return []\n",
    "    prefix = [s for s in SYMPTOMS if s.lower().startswith(q)]\n",
    "    substr = [s for s in SYMPTOMS if q in s.lower() and s not in prefix]\n",
    "    fuzzy  = difflib.get_close_matches(q, SYMPTOMS, n=k*2, cutoff=0.6)\n",
    "    fuzzy  = [s for s in fuzzy if s not in prefix and s not in substr]\n",
    "    out, seen = [], set()\n",
    "    for s in prefix + substr + fuzzy:\n",
    "        if s not in seen:\n",
    "            out.append(s); seen.add(s)\n",
    "        if len(out) >= k:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def resolve_exact(text):\n",
    "    return SYMPTOM_LOOKUP.get((text or \"\").strip().lower())\n",
    "\n",
    "# --- Widgets ---\n",
    "inp = widgets.Text(\n",
    "    placeholder=\"Type symptoms (e.g., 'burning urination; frequency; urgency')\",\n",
    "    description=\"Symptoms:\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "sugg_list = widgets.Select(\n",
    "    options=[],\n",
    "    rows=6,\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "pred_btn = widgets.Button(\n",
    "    description=\"Predict Common Group\",\n",
    "    button_style=\"info\",\n",
    "    layout=widgets.Layout(width=\"220px\", height=\"50px\")\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "# --- Events ---\n",
    "def on_text_change(change):\n",
    "    suggs = get_suggestions(change[\"new\"], k=12)\n",
    "    sugg_list.options = suggs\n",
    "\n",
    "def on_select_change(change):\n",
    "    if change[\"new\"]:\n",
    "        inp.value = change[\"new\"]\n",
    "\n",
    "def on_predict(_):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        user_text = (inp.value or \"\").strip()\n",
    "        if not user_text:\n",
    "            display(Markdown(\"> ⚠️ Please enter symptoms (or select from the suggestions).\"))\n",
    "            return\n",
    "\n",
    "        # 1) Try exact match\n",
    "        canon = resolve_exact(user_text)\n",
    "\n",
    "        # 2) Fallback: fuzzy match\n",
    "        matched_note = \"\"\n",
    "        if not canon:\n",
    "            best = difflib.get_close_matches(user_text, SYMPTOMS, n=1, cutoff=0.55)\n",
    "            if best:\n",
    "                canon = best[0]\n",
    "                matched_note = f\"\\n> *No exact match found. Using closest known symptoms:* `{canon}`\"\n",
    "            else:\n",
    "                display(Markdown(\"> ❌ No similar symptoms found in the CSV. Try typing differently or pick from suggestions.\"))\n",
    "                return\n",
    "\n",
    "        # Fetch all common disease groups for the matched symptom text\n",
    "        groups = sorted(set(df.loc[df[\"Symptoms\"] == canon, \"Common disease group\"].astype(str)))\n",
    "        if not groups:\n",
    "            display(Markdown(f\"> ❌ Couldn’t find a common disease group for symptoms: `{canon}`\"))\n",
    "            return\n",
    "\n",
    "        groups_md = \"\\n\".join([f\"- `{g}`\" for g in groups])\n",
    "        display(Markdown(\n",
    "f\"\"\"### 🧾 Predicted Common Disease Group\n",
    "**Entered symptoms:** `{user_text}`{matched_note}\n",
    "\n",
    "**Result(s):**\n",
    "{groups_md}\n",
    "\"\"\"\n",
    "        ))\n",
    "\n",
    "# Wire up\n",
    "inp.observe(on_text_change, names=\"value\")\n",
    "sugg_list.observe(on_select_change, names=\"value\")\n",
    "pred_btn.on_click(on_predict)\n",
    "\n",
    "# Initial render\n",
    "display(inp, sugg_list, pred_btn, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "100e34f6-b8df-4de5-b1cf-9bdc767a3600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e298adaafaed45f9bf3c8b76873e378b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Symptoms:', layout=Layout(width='80%'), placeholder=\"Type symptoms (e.g., 'burning…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b19638244f8467d95451862196c39f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(layout=Layout(width='80%'), options=(), rows=6, value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f798f864eeca444687b345ae04bba066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict Disease Group', layout=Layout(height='50px', width='220px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c144e46c97434822a736d6347480f1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict Disease Group from entered symptoms (with suggestions + fuzzy fallback)\n",
    "import pandas as pd, difflib\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "df[\"Symptoms\"] = df[\"Symptoms\"].astype(str)\n",
    "df[\"Disease Group\"] = df[\"Disease Group\"].astype(str)\n",
    "\n",
    "# Build unique symptom list and lookup\n",
    "SYMPTOMS = sorted(set(df[\"Symptoms\"].dropna().tolist()))\n",
    "SYMPTOM_LOOKUP = {s.strip().lower(): s for s in SYMPTOMS}\n",
    "\n",
    "# --- Suggestion helper (prefix + substring + fuzzy) ---\n",
    "def get_suggestions(query, k=12):\n",
    "    q = (query or \"\").strip().lower()\n",
    "    if not q:\n",
    "        return []\n",
    "    prefix = [s for s in SYMPTOMS if s.lower().startswith(q)]\n",
    "    substr = [s for s in SYMPTOMS if q in s.lower() and s not in prefix]\n",
    "    fuzzy  = difflib.get_close_matches(q, SYMPTOMS, n=k*2, cutoff=0.6)\n",
    "    fuzzy  = [s for s in fuzzy if s not in prefix and s not in substr]\n",
    "    out, seen = [], set()\n",
    "    for s in prefix + substr + fuzzy:\n",
    "        if s not in seen:\n",
    "            out.append(s); seen.add(s)\n",
    "        if len(out) >= k:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def resolve_exact(text):\n",
    "    return SYMPTOM_LOOKUP.get((text or \"\").strip().lower())\n",
    "\n",
    "# --- Widgets ---\n",
    "inp = widgets.Text(\n",
    "    placeholder=\"Type symptoms (e.g., 'burning urination; frequency; urgency')\",\n",
    "    description=\"Symptoms:\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "sugg_list = widgets.Select(\n",
    "    options=[],\n",
    "    rows=6,\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "pred_btn = widgets.Button(\n",
    "    description=\"Predict Disease Group\",\n",
    "    button_style=\"\",  # neutral style to differentiate from others\n",
    "    layout=widgets.Layout(width=\"220px\", height=\"50px\")\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "# --- Events ---\n",
    "def on_text_change(change):\n",
    "    suggs = get_suggestions(change[\"new\"], k=12)\n",
    "    sugg_list.options = suggs\n",
    "\n",
    "def on_select_change(change):\n",
    "    if change[\"new\"]:\n",
    "        inp.value = change[\"new\"]\n",
    "\n",
    "def on_predict(_):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        user_text = (inp.value or \"\").strip()\n",
    "        if not user_text:\n",
    "            display(Markdown(\"> ⚠️ Please enter symptoms (or select from the suggestions).\"))\n",
    "            return\n",
    "\n",
    "        # 1) Try exact match\n",
    "        canon = resolve_exact(user_text)\n",
    "\n",
    "        # 2) Fallback: fuzzy match\n",
    "        matched_note = \"\"\n",
    "        if not canon:\n",
    "            best = difflib.get_close_matches(user_text, SYMPTOMS, n=1, cutoff=0.55)\n",
    "            if best:\n",
    "                canon = best[0]\n",
    "                matched_note = f\"\\n> *No exact match found. Using closest known symptoms:* `{canon}`\"\n",
    "            else:\n",
    "                display(Markdown(\"> ❌ No similar symptoms found in the CSV. Try typing differently or pick from suggestions.\"))\n",
    "                return\n",
    "\n",
    "        # Fetch all disease groups for the matched symptom text\n",
    "        groups = sorted(set(df.loc[df[\"Symptoms\"] == canon, \"Disease Group\"].astype(str)))\n",
    "        if not groups:\n",
    "            display(Markdown(f\"> ❌ Couldn’t find a disease group for symptoms: `{canon}`\"))\n",
    "            return\n",
    "\n",
    "        groups_md = \"\\n\".join([f\"- `{g}`\" for g in groups])\n",
    "        display(Markdown(\n",
    "f\"\"\"### 🧾 Predicted Disease Group\n",
    "**Entered symptoms:** `{user_text}`{matched_note}\n",
    "\n",
    "**Result(s):**\n",
    "{groups_md}\n",
    "\"\"\"\n",
    "        ))\n",
    "\n",
    "# Wire up\n",
    "inp.observe(on_text_change, names=\"value\")\n",
    "sugg_list.observe(on_select_change, names=\"value\")\n",
    "pred_btn.on_click(on_predict)\n",
    "\n",
    "# Initial render\n",
    "display(inp, sugg_list, pred_btn, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f9e38bb-65ba-43e6-b34b-7410a14be26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b29242ffda04907895c82ca91db0dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Symptoms:', layout=Layout(width='80%'), placeholder=\"Type symptoms (e.g., 'burning…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bf9a193be849afbc886d4aa9038eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(layout=Layout(width='80%'), options=(), rows=6, value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11f2a7f33e14785b615715b8f66eb28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Predict Dosha Type', layout=Layout(height='50px', width='220px'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739c9f2ce3394fe39219d5b8923e2c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict Dosha Type from entered symptoms (with suggestions + fuzzy fallback)\n",
    "import re, difflib\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ------------- Load data -------------\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "df[\"Symptoms\"] = df[\"Symptoms\"].astype(str)\n",
    "\n",
    "# ------------- Ensure Dosha_Clean exists -------------\n",
    "ORDER = [\"vata\", \"pitta\", \"kapha\"]\n",
    "ORDER_SET = set(ORDER)\n",
    "\n",
    "def normalize_dosha(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    # Normalize \"tridosha\" variants\n",
    "    if \"tridosha\" in s or \"trisosha\" in s or re.search(r\"\\btri\\s*dosha\\b\", s):\n",
    "        return \"tridosha\"\n",
    "\n",
    "    # Unify separators -> '|' and strip junk\n",
    "    s = re.sub(r\"[;,+/]+\", \"|\", s)\n",
    "    s = s.replace(\" \", \"\")\n",
    "    s = re.sub(r\"[^a-z|]\", \"\", s)\n",
    "\n",
    "    parts = [p for p in s.split(\"|\") if p]\n",
    "    parts = [p for p in parts if p in ORDER_SET]\n",
    "    if not parts:\n",
    "        return pd.NA\n",
    "\n",
    "    present = [d for d in ORDER if d in parts]\n",
    "    if len(present) >= 3:\n",
    "        return \"tridosha\"\n",
    "    return \"|\".join(present)\n",
    "\n",
    "if \"Dosha_Clean\" not in df.columns:\n",
    "    if \"Dosha Types\" not in df.columns:\n",
    "        raise KeyError(\"CSV must include 'Dosha Types' or precomputed 'Dosha_Clean'.\")\n",
    "    df[\"Dosha_Clean\"] = df[\"Dosha Types\"].apply(normalize_dosha)\n",
    "\n",
    "# ------------- Suggestions setup -------------\n",
    "SYMPTOMS = sorted(set(df[\"Symptoms\"].dropna().tolist()))\n",
    "SYMPTOM_LOOKUP = {s.strip().lower(): s for s in SYMPTOMS}\n",
    "\n",
    "def get_suggestions(query, k=12):\n",
    "    q = (query or \"\").strip().lower()\n",
    "    if not q:\n",
    "        return []\n",
    "    prefix = [s for s in SYMPTOMS if s.lower().startswith(q)]\n",
    "    substr = [s for s in SYMPTOMS if q in s.lower() and s not in prefix]\n",
    "    fuzzy  = difflib.get_close_matches(q, SYMPTOMS, n=k*2, cutoff=0.6)\n",
    "    fuzzy  = [s for s in fuzzy if s not in prefix and s not in substr]\n",
    "    out, seen = [], set()\n",
    "    for s in prefix + substr + fuzzy:\n",
    "        if s not in seen:\n",
    "            out.append(s); seen.add(s)\n",
    "        if len(out) >= k:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def resolve_exact(text):\n",
    "    return SYMPTOM_LOOKUP.get((text or \"\").strip().lower())\n",
    "\n",
    "# ------------- Widgets -------------\n",
    "inp = widgets.Text(\n",
    "    placeholder=\"Type symptoms (e.g., 'burning urination; frequency; urgency')\",\n",
    "    description=\"Symptoms:\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "sugg_list = widgets.Select(\n",
    "    options=[],\n",
    "    rows=6,\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "pred_btn = widgets.Button(\n",
    "    description=\"Predict Dosha Type\",\n",
    "    button_style=\"warning\",\n",
    "    layout=widgets.Layout(width=\"220px\", height=\"50px\")\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "# ------------- Events -------------\n",
    "def on_text_change(change):\n",
    "    suggs = get_suggestions(change[\"new\"], k=12)\n",
    "    sugg_list.options = suggs\n",
    "\n",
    "def on_select_change(change):\n",
    "    if change[\"new\"]:\n",
    "        inp.value = change[\"new\"]\n",
    "\n",
    "def on_predict(_):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        user_text = (inp.value or \"\").strip()\n",
    "        if not user_text:\n",
    "            display(Markdown(\"> ⚠️ Please enter symptoms (or select from the suggestions).\"))\n",
    "            return\n",
    "\n",
    "        # Exact first, then fuzzy\n",
    "        canon = resolve_exact(user_text)\n",
    "        matched_note = \"\"\n",
    "        if not canon:\n",
    "            best = difflib.get_close_matches(user_text, SYMPTOMS, n=1, cutoff=0.55)\n",
    "            if best:\n",
    "                canon = best[0]\n",
    "                matched_note = f\"\\n> *No exact match found. Using closest known symptoms:* `{canon}`\"\n",
    "            else:\n",
    "                display(Markdown(\"> ❌ No similar symptoms found in the CSV. Try typing differently or pick from suggestions.\"))\n",
    "                return\n",
    "\n",
    "        # Collect dosha types (show cleaned + optionally original if present)\n",
    "        sub = df.loc[df[\"Symptoms\"] == canon, :]\n",
    "        dosha_clean = sorted(set(sub[\"Dosha_Clean\"].dropna().astype(str)))\n",
    "        dosha_orig  = []\n",
    "        if \"Dosha Types\" in sub.columns:\n",
    "            dosha_orig = sorted(set(sub[\"Dosha Types\"].dropna().astype(str)))\n",
    "\n",
    "        if not dosha_clean and not dosha_orig:\n",
    "            display(Markdown(f\"> ❌ Couldn’t find a dosha type for symptoms: `{canon}`\"))\n",
    "            return\n",
    "\n",
    "        # Render\n",
    "        lines = []\n",
    "        if dosha_clean:\n",
    "            lines.append(\"**Dosha (cleaned):** \" + \", \".join(f\"`{d}`\" for d in dosha_clean))\n",
    "        if dosha_orig:\n",
    "            lines.append(\"**Dosha (original):** \" + \", \".join(f\"`{d}`\" for d in dosha_orig))\n",
    "\n",
    "        display(Markdown(\n",
    "f\"\"\"### 🧾 Predicted Dosha Type\n",
    "**Entered symptoms:** `{user_text}`{matched_note}\n",
    "\n",
    "{'<br>'.join(lines)}\n",
    "\"\"\"\n",
    "        ))\n",
    "\n",
    "# Wire up\n",
    "inp.observe(on_text_change, names=\"value\")\n",
    "sugg_list.observe(on_select_change, names=\"value\")\n",
    "pred_btn.on_click(on_predict)\n",
    "\n",
    "# Initial render\n",
    "display(inp, sugg_list, pred_btn, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bef54ff-3544-4518-b1ba-e1495dd83a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4820116947473eadc61b5c8b6ebb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Symptom:', layout=Layout(width='80%'), placeholder='Type or pick a symptom…')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a73ebf780c04c1ab0bfcd303e083ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(layout=Layout(width='80%'), options=(), rows=6, value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb91fe520df4bad9d4a80ceb84d4cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Predict Risk', layout=Layout(height='55px', width='220px'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0f3d125a3f4599aa790461aad87f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Suggestions (clickable list) + Predict full risk (Common disease group + Disease Group + cleaned dosha)\n",
    "import re, difflib\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ---------------------------\n",
    "# Load data\n",
    "# ---------------------------\n",
    "df = pd.read_csv(\"data/symptoms.csv\")\n",
    "df.rename(columns=lambda c: str(c).strip(), inplace=True)\n",
    "\n",
    "SYMPTOM_COL = \"Symptom\" if \"Symptom\" in df.columns else \"Symptoms\"\n",
    "if SYMPTOM_COL not in df.columns:\n",
    "    raise KeyError(\"Expected 'Symptom' or 'Symptoms' column in CSV.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Dosha normalization\n",
    "# ---------------------------\n",
    "ORDER = [\"vata\", \"pitta\", \"kapha\"]\n",
    "ORDER_SET = set(ORDER)\n",
    "\n",
    "def normalize_dosha(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    if \"tridosha\" in s or \"trisosha\" in s or re.search(r\"\\btri\\s*dosha\\b\", s):\n",
    "        return \"tridosha\"\n",
    "\n",
    "    s = re.sub(r\"[;,+/]+\", \"|\", s)\n",
    "    s = s.replace(\" \", \"\")\n",
    "    s = re.sub(r\"[^a-z|]\", \"\", s)\n",
    "\n",
    "    parts = [p for p in s.split(\"|\") if p]\n",
    "    parts = [p for p in parts if p in ORDER_SET]\n",
    "    if not parts:\n",
    "        return pd.NA\n",
    "\n",
    "    present = [d for d in ORDER if d in parts]\n",
    "    if len(present) >= 3:\n",
    "        return \"tridosha\"\n",
    "    return \"|\".join(present)\n",
    "\n",
    "if \"Dosha_Clean\" not in df.columns:\n",
    "    if \"Dosha Types\" not in df.columns and \"Dosha types\" not in df.columns:\n",
    "        raise KeyError(\"Expected 'Dosha_Clean' or 'Dosha Types' column in CSV.\")\n",
    "    dosha_col = \"Dosha Types\" if \"Dosha Types\" in df.columns else \"Dosha types\"\n",
    "    df[\"Dosha_Clean\"] = df[dosha_col].apply(normalize_dosha)\n",
    "\n",
    "# ---------------------------\n",
    "# Weights\n",
    "# ---------------------------\n",
    "disease_group_weight = {\n",
    "    \"Urinary tract infections\":              4,\n",
    "    \"Muscular disorders\":                    5,\n",
    "    \"Cardiomyopathies\":                      7,\n",
    "    \"Cardiovascular diseases\":               9,\n",
    "    \"Ear diseases\":                          3,\n",
    "    \"Eye diseases\":                          4,\n",
    "    \"Hematological diseases\":                6,\n",
    "    \"Liver disease\":                         7,\n",
    "    \"Mental health / Psychiatric disorders\": 6,\n",
    "    \"Nutritional Deficiency Diseases\":       4,\n",
    "    \"Reproductive system diseases\":          5,\n",
    "    \"Tropical diseases\":                     6,\n",
    "    \"Endocrine and Metabolic Diseases\":      7,\n",
    "    \"Cancer and neoplasms\":                  9,\n",
    "    \"Zoonotic diseases\":                     6,\n",
    "}\n",
    "\n",
    "dosha_weight = {\n",
    "    \"vata\":        7.5,\n",
    "    \"pitta\":       8.0,\n",
    "    \"kapha\":       6.5,\n",
    "    \"vata|pitta\":  8.5,\n",
    "    \"vata|kapha\":  7.0,\n",
    "    \"pitta|kapha\": 8.0,\n",
    "    \"tridosha\":    9.5,\n",
    "}\n",
    "\n",
    "W_GROUP = 0.6\n",
    "W_DOSHA = 0.4\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "SYMPTOMS = sorted(set(df[SYMPTOM_COL].dropna().astype(str).tolist()))\n",
    "SYMPTOM_LOOKUP = {s.strip().lower(): s for s in SYMPTOMS}\n",
    "\n",
    "def resolve_exact(text: str):\n",
    "    return SYMPTOM_LOOKUP.get((text or \"\").strip().lower())\n",
    "\n",
    "def get_suggestions(query, k=12):\n",
    "    q = (query or \"\").strip().lower()\n",
    "    if not q:\n",
    "        return []\n",
    "    prefix = [s for s in SYMPTOMS if s.lower().startswith(q)]\n",
    "    substr = [s for s in SYMPTOMS if q in s.lower() and s not in prefix]\n",
    "    fuzzy  = difflib.get_close_matches(q, SYMPTOMS, n=k*2, cutoff=0.6)\n",
    "    fuzzy  = [s for s in fuzzy if s not in prefix and s not in substr]\n",
    "    out, seen = [], set()\n",
    "    for s in prefix + substr + fuzzy:\n",
    "        if s not in seen:\n",
    "            out.append(s); seen.add(s)\n",
    "        if len(out) >= k:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def risk_level_from_score(score: float):\n",
    "    if score < 4:\n",
    "        return \"🟢 Low Risk\"\n",
    "    elif score < 7:\n",
    "        return \"🟠 Medium Risk\"\n",
    "    else:\n",
    "        return \"🔴 High Risk\"\n",
    "\n",
    "def compute_risk_for_symptom(symptom_text: str, w_group=W_GROUP, w_dosha=W_DOSHA):\n",
    "    canon = resolve_exact(symptom_text)\n",
    "    if not canon:\n",
    "        return {\"found\": False, \"message\": \"Symptom not found.\"}\n",
    "\n",
    "    row = df.loc[df[SYMPTOM_COL] == canon].iloc[0]\n",
    "    common_group = str(row[\"Common disease group\"])\n",
    "    disease_group = str(row[\"Disease Group\"])\n",
    "    dosha = str(row[\"Dosha_Clean\"])\n",
    "\n",
    "    g_w = float(disease_group_weight.get(common_group, 0.0))\n",
    "    d_w = float(dosha_weight.get(dosha, 0.0))\n",
    "\n",
    "    score = round(w_group * g_w + w_dosha * d_w, 2)\n",
    "    level = risk_level_from_score(score)\n",
    "\n",
    "    return {\n",
    "        \"found\": True,\n",
    "        \"symptom\": canon,\n",
    "        \"common_group\": common_group,\n",
    "        \"disease_group\": disease_group,\n",
    "        \"dosha\": dosha,\n",
    "        \"group_weight\": g_w,\n",
    "        \"dosha_weight\": d_w,\n",
    "        \"formula\": f\"Risk = {w_group}×{g_w} + {w_dosha}×{d_w}\",\n",
    "        \"risk_score_0_10\": score,\n",
    "        \"risk_level\": level\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Widgets\n",
    "# ---------------------------\n",
    "inp = widgets.Text(\n",
    "    placeholder=\"Type or pick a symptom…\",\n",
    "    description=\"Symptom:\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "sugg_list = widgets.Select(options=[], rows=6, layout=widgets.Layout(width=\"80%\"))\n",
    "\n",
    "pred_btn = widgets.Button(\n",
    "    description=\"Predict Risk\",\n",
    "    button_style=\"success\",\n",
    "    layout=widgets.Layout(width=\"220px\", height=\"55px\")\n",
    ")\n",
    "pred_btn.style.button_color = \"#4CAF50\"\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "# ---------------------------\n",
    "# Wire up\n",
    "# ---------------------------\n",
    "def on_text_change(change):\n",
    "    sugg_list.options = get_suggestions(change[\"new\"], k=12)\n",
    "\n",
    "def on_select_change(change):\n",
    "    if change[\"new\"]:\n",
    "        inp.value = change[\"new\"]\n",
    "\n",
    "def on_predict(_):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        res = compute_risk_for_symptom(inp.value)\n",
    "        if not res.get(\"found\"):\n",
    "            display(Markdown(\"> ⚠️ Please select a valid symptom.\"))\n",
    "            return\n",
    "\n",
    "        display(Markdown(\n",
    "f\"\"\"### 🧾 Risk Assessment\n",
    "**Symptom:** `{res['symptom']}`  \n",
    "**Common Disease Group:** `{res['common_group']}`  \n",
    "**Disease Group:** `{res['disease_group']}`  \n",
    "**Dosha (cleaned):** `{res['dosha']}`  \n",
    "\n",
    "**Group Weight:** `{res['group_weight']}`  \n",
    "**Dosha Weight:** `{res['dosha_weight']}`  \n",
    "\n",
    "**Formula:** `{res['formula']}`  \n",
    "**Risk Score (0–10):** `{res['risk_score_0_10']}`  \n",
    "**Risk Level:** **{res['risk_level']}**\"\"\"\n",
    "        ))\n",
    "\n",
    "inp.observe(on_text_change, names=\"value\")\n",
    "sugg_list.observe(on_select_change, names=\"value\")\n",
    "pred_btn.on_click(on_predict)\n",
    "\n",
    "display(inp, sugg_list, pred_btn, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dab199-655f-4c8c-8ea7-950e7e4d98e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
